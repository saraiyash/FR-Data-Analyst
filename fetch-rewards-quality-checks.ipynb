{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Checks\n",
    "#### 1. Initialize\n",
    "As we have already flattened the JSON files into their respective .csv files along with converting the UNIX timestamp to a more recognizable format, we will begin to analyze and perform checks on other sections of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id.$oid</th>\n",
       "      <th>active</th>\n",
       "      <th>createdDate.$date</th>\n",
       "      <th>lastLogin.$date</th>\n",
       "      <th>role</th>\n",
       "      <th>signUpSource</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ff1e194b6a9d73a3a9f1052</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-03 15:24:04</td>\n",
       "      <td>2021-01-03 15:25:37</td>\n",
       "      <td>consumer</td>\n",
       "      <td>Email</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ff1e194b6a9d73a3a9f1052</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-03 15:24:04</td>\n",
       "      <td>2021-01-03 15:25:37</td>\n",
       "      <td>consumer</td>\n",
       "      <td>Email</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ff1e194b6a9d73a3a9f1052</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-03 15:24:04</td>\n",
       "      <td>2021-01-03 15:25:37</td>\n",
       "      <td>consumer</td>\n",
       "      <td>Email</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ff1e1eacfcf6c399c274ae6</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-03 15:25:30</td>\n",
       "      <td>2021-01-03 15:25:30</td>\n",
       "      <td>consumer</td>\n",
       "      <td>Email</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ff1e194b6a9d73a3a9f1052</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-03 15:24:04</td>\n",
       "      <td>2021-01-03 15:25:37</td>\n",
       "      <td>consumer</td>\n",
       "      <td>Email</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id.$oid  active    createdDate.$date      lastLogin.$date  \\\n",
       "0  5ff1e194b6a9d73a3a9f1052    True  2021-01-03 15:24:04  2021-01-03 15:25:37   \n",
       "1  5ff1e194b6a9d73a3a9f1052    True  2021-01-03 15:24:04  2021-01-03 15:25:37   \n",
       "2  5ff1e194b6a9d73a3a9f1052    True  2021-01-03 15:24:04  2021-01-03 15:25:37   \n",
       "3  5ff1e1eacfcf6c399c274ae6    True  2021-01-03 15:25:30  2021-01-03 15:25:30   \n",
       "4  5ff1e194b6a9d73a3a9f1052    True  2021-01-03 15:24:04  2021-01-03 15:25:37   \n",
       "\n",
       "       role signUpSource state  \n",
       "0  consumer        Email    WI  \n",
       "1  consumer        Email    WI  \n",
       "2  consumer        Email    WI  \n",
       "3  consumer        Email    WI  \n",
       "4  consumer        Email    WI  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id.$oid</th>\n",
       "      <th>active</th>\n",
       "      <th>createdDate.$date</th>\n",
       "      <th>lastLogin.$date</th>\n",
       "      <th>role</th>\n",
       "      <th>signUpSource</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>54943462e4b07e684157a532</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-12-19 14:21:22</td>\n",
       "      <td>2021-03-05 16:52:23</td>\n",
       "      <td>fetch-staff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>54943462e4b07e684157a532</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-12-19 14:21:22</td>\n",
       "      <td>2021-03-05 16:52:23</td>\n",
       "      <td>fetch-staff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>54943462e4b07e684157a532</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-12-19 14:21:22</td>\n",
       "      <td>2021-03-05 16:52:23</td>\n",
       "      <td>fetch-staff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>54943462e4b07e684157a532</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-12-19 14:21:22</td>\n",
       "      <td>2021-03-05 16:52:23</td>\n",
       "      <td>fetch-staff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>54943462e4b07e684157a532</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-12-19 14:21:22</td>\n",
       "      <td>2021-03-05 16:52:23</td>\n",
       "      <td>fetch-staff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _id.$oid  active    createdDate.$date  \\\n",
       "490  54943462e4b07e684157a532    True  2014-12-19 14:21:22   \n",
       "491  54943462e4b07e684157a532    True  2014-12-19 14:21:22   \n",
       "492  54943462e4b07e684157a532    True  2014-12-19 14:21:22   \n",
       "493  54943462e4b07e684157a532    True  2014-12-19 14:21:22   \n",
       "494  54943462e4b07e684157a532    True  2014-12-19 14:21:22   \n",
       "\n",
       "         lastLogin.$date         role signUpSource state  \n",
       "490  2021-03-05 16:52:23  fetch-staff          NaN   NaN  \n",
       "491  2021-03-05 16:52:23  fetch-staff          NaN   NaN  \n",
       "492  2021-03-05 16:52:23  fetch-staff          NaN   NaN  \n",
       "493  2021-03-05 16:52:23  fetch-staff          NaN   NaN  \n",
       "494  2021-03-05 16:52:23  fetch-staff          NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "df_users = pd.read_csv('data/users.csv')\n",
    "display(df_users.head())\n",
    "display(df_users.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Rename columns or variables\n",
    "Now, we check the data dictionary and the types assigned to the dataset. Along with this, we will rename some of these columns for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              object\n",
       "active            bool\n",
       "createdDate     object\n",
       "lastLogin       object\n",
       "role            object\n",
       "signUpSource    object\n",
       "state           object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_users = df_users.rename(columns=\n",
    "                           {\n",
    "                               '_id.$oid': 'id', 'createdDate.$date': 'createdDate', 'lastLogin.$date': 'lastLogin' \n",
    "                           })\n",
    "display(df_users.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check for duplicate rows or records\n",
    "Some common issues with a dataset are that it might contain multiple duplicated rows which presents an incorrect idea about the dimensions and the size of the dataset.\n",
    "\n",
    "If we find duplicated rows, we will drop these duplicates to simplify our dataset. Moreover, duplicate rows could indicate stale  or incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual shape v/s Duplicated shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((495, 7), (283, 7))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows_df = df_users[df_users.duplicated()]\n",
    "\n",
    "print(\"Actual shape v/s Duplicated shape\")\n",
    "df_users.shape, duplicate_rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id              495\n",
       "active          495\n",
       "createdDate     495\n",
       "lastLogin       433\n",
       "role            495\n",
       "signUpSource    447\n",
       "state           439\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping duplicates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id              212\n",
       "active          212\n",
       "createdDate     212\n",
       "lastLogin       172\n",
       "role            212\n",
       "signUpSource    207\n",
       "state           206\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Before dropping duplicates\")\n",
    "display(df_users.count())\n",
    "df_users = df_users.drop_duplicates()\n",
    "\n",
    "print(\"After dropping duplicates\")\n",
    "display(df_users.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check for NA values (NaN values)\n",
    "Generally, we check for NaN and NULL values in our dataset and we replace them with better values in a process called Imputation. At times, these values can be simply replaced by a '0' and other times, it is best to populate an average value to it.\n",
    "\n",
    "In some scenarios, if these values are not harmful, they are kept as is.\n",
    "\n",
    "In this case, NA values were not dropped. <u>Further action could be taken based on response from the business stakeholders.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original count including NA values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id              212\n",
       "active          212\n",
       "createdDate     212\n",
       "lastLogin       172\n",
       "role            212\n",
       "signUpSource    207\n",
       "state           206\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count after dropping NA values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id              165\n",
       "active          165\n",
       "createdDate     165\n",
       "lastLogin       165\n",
       "role            165\n",
       "signUpSource    165\n",
       "state           165\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nulls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "active           0\n",
       "createdDate      0\n",
       "lastLogin       40\n",
       "role             0\n",
       "signUpSource     5\n",
       "state            6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original count including NA values\")\n",
    "display(df_users.count())\n",
    "\n",
    "temp = df_users.dropna()\n",
    "\n",
    "print(\"Count after dropping NA values\")\n",
    "display(temp.count())\n",
    "\n",
    "print(\"Total nulls\")\n",
    "df_users.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Individual checks for each column using unique(), min(), max()\n",
    "We will now embark on analyzing each of these attributes/columns individually. Find out their range if data is numeric, if the values are categorical, we check to see if the categories mentioned are correctly stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values of:\n",
      "id=212\n",
      "active=2\n",
      "createdDate=212\n",
      "lastLogin=172\n",
      "role=2\n",
      "signUpSource=3\n",
      "state=9\n",
      "\n",
      "Categorical data\n",
      "active\n",
      "[ True False]\n",
      "-----------------------\n",
      "role\n",
      "['consumer' 'fetch-staff']\n",
      "-----------------------\n",
      "signUpSource\n",
      "['Email' 'Google' nan]\n",
      "-----------------------\n",
      "state\n",
      "['WI' 'KY' 'AL' 'CO' 'IL' nan 'OH' 'SC' 'NH']\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Distinct values of:\")\n",
    "for col in df_users.columns:\n",
    "    print(col+'=' + str(len(pd.unique(df_users[col]))))\n",
    "\n",
    "print()\n",
    "print(\"Categorical data\")\n",
    "lets_check_for = ['active', 'role', 'signUpSource', 'state']\n",
    "for col in lets_check_for:\n",
    "    print(col)\n",
    "    print(pd.unique(df_users[col]))\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of createdDate values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Timestamp('2021-02-12 14:11:06'), Timestamp('2014-12-19 14:21:22'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Range of createdDate values\")\n",
    "df_users[\"createdDate\"].astype('datetime64[ns]').max(), df_users[\"createdDate\"].astype('datetime64[ns]').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of lastLogin values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Timestamp('2021-03-05 16:52:23'), Timestamp('2018-05-07 17:23:40'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Range of lastLogin values\")\n",
    "df_users[\"lastLogin\"].astype('datetime64[ns]').max(), df_users[\"lastLogin\"].astype('datetime64[ns]').min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Criteria for measuring data quality:\n",
    "##### 1. Accuracy\n",
    "<u>a.</u> Duplication of records was noticed in the dataset. Total duplicate records in the dataset = 283. These records were dropped eventually. However, this could be an indicator of stale or inaccurate data.\n",
    "\n",
    "<u>ACTION</u> - Reach out to the business stakeholders as well as the source system teams about the duplicates.\n",
    "\n",
    "<u>b.</u> Almost all the other columns mentioned in the data dictionary met the required criteria except for the role column. The role column is a constant set to \"consumer‚Äù; however, we can also see that some rows have \"fetch-staff\" value present.\n",
    "\n",
    "<u>ACTION</u> - Ask the business stakeholders whether this is expected. Presumably, some of the actual FR staff have accessed this data and hence, this value is assigned to the records edited by the FR staff.\n",
    "\n",
    "##### 2. Relevancy\n",
    "<u>a.</u> Ask the business stakeholders whether this is expected. Presumably, some of the actual FR staff have accessed this data and hence, this value is assigned to the records edited by the FR staff.\n",
    "\n",
    "##### 3. Completeness\n",
    "<u>a.</u> Incomplete records were found as there were multiple columns with NA/NaN and NULL values present. This could be a problem from the source of the dataset itself.  \n",
    "\n",
    "<u>ACTION</u> - Ask the source system team to investigate this issue with missing values or data.\n",
    "\n",
    "##### 4. Timeliness\n",
    "<u>a.</u> Based on the 2 columns that provide date-based information, the latest update in the dataset is from 2021-03-05.\n",
    "\n",
    "<u>ACTION</u> - Need confirmation on whether this is the latest cut-off date for the dataset or if more recent data somehow went missing, pending further investigation.\n",
    "\n",
    "##### 5. Consistency\n",
    "<u>a.</u> No major issues with consistency of the data. Minor issue - date attributes are present in UNIX time. Need to confirm whether this is expected and consistent with other datasets. All the other files also were in the same UNIX time format which makes this a non-issue.\n",
    "\n",
    "<u>ACTION</u> - Ask the business stakeholders and the source system team why the date format is set to UNIX time format.\n",
    "\n",
    "##### References\n",
    "Data Dictionary - https://fetch-hiring.s3.amazonaws.com/data-analyst/ineeddata-data-modeling/data-modeling.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
